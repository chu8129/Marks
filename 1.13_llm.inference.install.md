### vllm 0.4.1
source /etc/network_turbo
TMPDIR=/dev/shm pip3 install --cache-dir=/dev/shm -U torch==2.2.1 torchvision==0.17.1 torchaudio==2.2.1 --index-url https://download.pytorch.org/whl/cu121
TMPDIR=/dev/shm pip3 install --cache-dir=/dev/shm -U pip install torchsde
TMPDIR=/dev/shm pip3 install --cache-dir=/dev/shm -U pip install vllm==0.4.1
TMPDIR=/dev/shm pip3 install --cache-dir=/dev/shm -U git+https://github.com/huggingface/transformers.git
TMPDIR=/dev/shm pip3 install --cache-dir=/dev/shm -U git+https://github.com/huggingface/peft.git
TMPDIR=/dev/shm pip3 install --cache-dir=/dev/shm -U git+https://github.com/Dao-AILab/flash-attention.git --no-build-isolation


### exllamav2
TMPDIR=/dev/shm pip3 install --cache-dir=/dev/shm -U pip install exllamav2
pip install -U torch==2.2.2 torchvision==0.17.2 torchaudio==2.2.2 --index-url https://download.pytorch.org/whl/cu118
pip install -U git+https://github.com/huggingface/transformers.git
pip install -U git+https://github.com/huggingface/peft.git
pip install -U git+https://github.com/Dao-AILab/flash-attention.git

### vllm 0.5.3
source /etc/network_turbo
TMPDIR=/dev/shm pip3 install --cache-dir=/dev/shm -U torch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1 torchsde --index-url https://download.pytorch.org/whl/cu121
TMPDIR=/dev/shm pip3 install --cache-dir=/dev/shm -U pip install vllm==0.5.3
TMPDIR=/dev/shm pip3 install --cache-dir=/dev/shm -U git+https://github.com/huggingface/transformers.git
TMPDIR=/dev/shm pip3 install --cache-dir=/dev/shm -U git+https://github.com/huggingface/peft.git
TMPDIR=/dev/shm pip3 install --cache-dir=/dev/shm -U git+https://github.com/Dao-AILab/flash-attention.git --no-build-isolation
